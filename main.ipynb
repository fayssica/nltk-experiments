{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK experiments \n",
    "based on [NLTK with Python 3 for Natural Language Processing](https://www.youtube.com/playlist?list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL) by Sentdex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: we don't relly want to download packages each time when we lauch this script\n",
    "# so it'll better to check somehow whether we have packages or not - or Download on demand\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing\n",
    "based on \n",
    "- https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/\n",
    "- [youtube](https://www.youtube.com/watch?v=FLZvOKSCkxY&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = 'Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. ' \\\n",
    "          'The sky is pinkish-blue. You shouldn\\'t eat cardboard.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Mr. Smith, how are you doing today?',\n",
       " 'The weather is great, and Python is awesome.',\n",
       " 'The sky is pinkish-blue.',\n",
       " \"You shouldn't eat cardboard.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.sent_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Mr.',\n",
       " 'Smith',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " 'today',\n",
       " '?',\n",
       " 'The',\n",
       " 'weather',\n",
       " 'is',\n",
       " 'great',\n",
       " ',',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'is',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'The',\n",
       " 'sky',\n",
       " 'is',\n",
       " 'pinkish-blue',\n",
       " '.',\n",
       " 'You',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'eat',\n",
       " 'cardboard',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.word_tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stop words\n",
    "- [sources](https://pythonprogramming.net/stop-words-nltk-tutorial/)\n",
    "- [video](https://www.youtube.com/watch?v=w36-U-ccajM&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import corpus, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sentence = 'This is a sample sentence, showing off the stop words filtration.'\n",
    "stop_words = set(corpus.stopwords.words('english'))\n",
    "words = tokenize.word_tokenize(example_sentence)\n",
    "filtered_sentence = [w for w in words if w not in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "- [source](https://pythonprogramming.net/stemming-nltk-tutorial/)\n",
    "- [video](https://www.youtube.com/watch?v=yGKTphqxR9Q&index=3&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import stem, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = stem.PorterStemmer()\n",
    "example_words = ['python', 'pythoner', 'pythoning', 'pythoned', 'pythonly', 'pythonic', 'pythonista']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python --> python',\n",
       " 'pythoner --> python',\n",
       " 'pythoning --> python',\n",
       " 'pythoned --> python',\n",
       " 'pythonly --> pythonli',\n",
       " 'pythonic --> python',\n",
       " 'pythonista --> pythonista']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['{} --> {}'.format(w, ps.stem(w)) for w in example_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_text = 'It is important to by very pythonly while you are pythoning with python. '\\\n",
    "               'All pythoners have pythoned poorly at least once.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It --> It',\n",
       " 'is --> is',\n",
       " 'important --> import',\n",
       " 'to --> to',\n",
       " 'by --> by',\n",
       " 'very --> veri',\n",
       " 'pythonly --> pythonli',\n",
       " 'while --> while',\n",
       " 'you --> you',\n",
       " 'are --> are',\n",
       " 'pythoning --> python',\n",
       " 'with --> with',\n",
       " 'python --> python',\n",
       " '. --> .',\n",
       " 'All --> all',\n",
       " 'pythoners --> python',\n",
       " 'have --> have',\n",
       " 'pythoned --> python',\n",
       " 'poorly --> poorli',\n",
       " 'at --> at',\n",
       " 'least --> least',\n",
       " 'once --> onc',\n",
       " '. --> .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['{} --> {}'.format(w, ps.stem(w)) for w in tokenize.word_tokenize(example_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging\n",
    "- [source](https://pythonprogramming.net/part-of-speech-tagging-nltk-tutorial/)\n",
    "- [video](https://www.youtube.com/watch?v=6j6M2MtEqi8&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&index=4)\n",
    "\n",
    "```\n",
    "POS tag list:\n",
    "\n",
    "CC\tcoordinating conjunction\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW\tforeign word\n",
    "IN\tpreposition/subordinating conjunction\n",
    "JJ\tadjective\t'big'\n",
    "JJR\tadjective, comparative\t'bigger'\n",
    "JJS\tadjective, superlative\t'biggest'\n",
    "LS\tlist marker\t1)\n",
    "MD\tmodal\tcould, will\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "PDT\tpredeterminer\t'all tdhe kids'\n",
    "POS\tpossessive ending\tparent's\n",
    "PRP\tpersonal pronound√ü\tI, he, she\n",
    "PRP$\tpossessive pronoun\tmy, his, hers\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "RP\tparticle\tgive up\n",
    "TO\tto\tgo 'to' the store.\n",
    "UH\tinterjection\terrrrrrrrm\n",
    "VB\tverb, base form\ttake\n",
    "VBD\tverb, past tense\ttook\n",
    "VBG\tverb, gerund/present participle\ttaking\n",
    "VBN\tverb, past participle\ttaken\n",
    "VBP\tverb, sing. present, non-3d\ttake\n",
    "VBZ\tverb, 3rd person sing. present\ttakes\n",
    "WDT\twh-determiner\twhich\n",
    "WP\twh-pronoun\twho, what\n",
    "WP$\tpossessive wh-pronoun\twhose\n",
    "WRB\twh-abverb\twhere, when\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import corpus, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = corpus.state_union.raw('2005-GWBush.txt')\n",
    "sample_text = corpus.state_union.raw('2006-GWBush.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map tag to description, useful for annotations\n",
    "tag_to_description = {\n",
    "    'CC': 'coordinating conjunction',\n",
    "    'CD': 'cardinal digit',\n",
    "    'DT': 'determiner',\n",
    "    'EX': 'existential there (like: \"there is\" ... think of it like \"there exists\")',\n",
    "    'FW': 'foreign word',\n",
    "    'IN': 'preposition/subordinating conjunction',\n",
    "    'JJ': 'adjective\t\"big\"',\n",
    "    'JJR': 'adjective, comparative\t\"bigger\"',\n",
    "    'JJS': 'adjective, superlative\t\"biggest\"',\n",
    "    'LS': 'list marker\t1)',\n",
    "    'MD': 'modal\tcould, will',\n",
    "    'NN': 'noun, singular \"desk\"',\n",
    "    'NNS': 'noun plural\t\"desks\"',\n",
    "    'NNP': 'proper noun, singular\t\"Harrison\"',\n",
    "    'NNPS': 'proper noun, plural\t\"Americans\"',\n",
    "    'PDT': 'predeterminer\t\"all tdhe kids\"',\n",
    "    'POS': 'possessive ending\tparent\"s',\n",
    "    'PRP': 'personal pronound√ü\tI, he, she',\n",
    "    'PRP$': 'possessive pronoun\tmy, his, hers',\n",
    "    'RB': 'adverb\tvery, silently,',\n",
    "    'RBR': 'adverb, comparative\tbetter',\n",
    "    'RBS': 'adverb, superlative\tbest',\n",
    "    'RP': 'particle\tgive up',\n",
    "    'TO': 'to\tgo \"to\" the store.',\n",
    "    'UH': 'interjection\terrrrrrrrm',\n",
    "    'VB': 'verb, base form\ttake',\n",
    "    'VBD': 'verb, past tense\ttook',\n",
    "    'VBG': 'verb, gerund/present participle\ttaking',\n",
    "    'VBN': 'verb, past participle\ttaken',\n",
    "    'VBP': 'verb, sing. present, non-3d\ttake',\n",
    "    'VBZ': 'verb, 3rd person sing. present\ttakes',\n",
    "    'WDT': 'wh-determiner\twhich',\n",
    "    'WP': 'wh-pronoun\twho, what',\n",
    "    'WP$': 'possessive wh-pronoun\twhose',\n",
    "    'WRB': 'wh-abverb\twhere, when',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sentence:\n",
      "PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "January 31, 2006\n",
      "\n",
      "THE PRESIDENT: Thank you all.\n",
      "# Words:\n",
      "['PRESIDENT', 'GEORGE', 'W.', 'BUSH', \"'S\", 'ADDRESS', 'BEFORE', 'A', 'JOINT', 'SESSION', 'OF', 'THE', 'CONGRESS', 'ON', 'THE', 'STATE', 'OF', 'THE', 'UNION', 'January', '31', ',', '2006', 'THE', 'PRESIDENT', ':', 'Thank', 'you', 'all', '.']\n",
      "# Tagged:\n",
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "Mr. Speaker, Vice President Cheney, members of Congress, members of the Supreme Court and diplomatic corps, distinguished guests, and fellow citizens: Today our nation lost a beloved, graceful, courageous woman who called America to its founding ideals and carried on a noble dream.\n",
      "# Words:\n",
      "['Mr.', 'Speaker', ',', 'Vice', 'President', 'Cheney', ',', 'members', 'of', 'Congress', ',', 'members', 'of', 'the', 'Supreme', 'Court', 'and', 'diplomatic', 'corps', ',', 'distinguished', 'guests', ',', 'and', 'fellow', 'citizens', ':', 'Today', 'our', 'nation', 'lost', 'a', 'beloved', ',', 'graceful', ',', 'courageous', 'woman', 'who', 'called', 'America', 'to', 'its', 'founding', 'ideals', 'and', 'carried', 'on', 'a', 'noble', 'dream', '.']\n",
      "# Tagged:\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "Tonight we are comforted by the hope of a glad reunion with the husband who was taken so long ago, and we are grateful for the good life of Coretta Scott King.\n",
      "# Words:\n",
      "['Tonight', 'we', 'are', 'comforted', 'by', 'the', 'hope', 'of', 'a', 'glad', 'reunion', 'with', 'the', 'husband', 'who', 'was', 'taken', 'so', 'long', 'ago', ',', 'and', 'we', 'are', 'grateful', 'for', 'the', 'good', 'life', 'of', 'Coretta', 'Scott', 'King', '.']\n",
      "# Tagged:\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "(Applause.)\n",
      "# Words:\n",
      "['(', 'Applause', '.', ')']\n",
      "# Tagged:\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "President George W. Bush reacts to applause during his State of the Union Address at the Capitol, Tuesday, Jan.\n",
      "# Words:\n",
      "['President', 'George', 'W.', 'Bush', 'reacts', 'to', 'applause', 'during', 'his', 'State', 'of', 'the', 'Union', 'Address', 'at', 'the', 'Capitol', ',', 'Tuesday', ',', 'Jan', '.']\n",
      "# Tagged:\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Counts:\n",
      "0.29577464788732394\n",
      "[NNP] proper noun, singular\t\"Harrison\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.09859154929577464\n",
      "[IN] preposition/subordinating conjunction\n",
      "\n",
      "-----\n",
      "\n",
      "0.07746478873239436\n",
      "[,] ,\n",
      "\n",
      "-----\n",
      "\n",
      "0.07042253521126761\n",
      "[DT] determiner\n",
      "\n",
      "-----\n",
      "\n",
      "0.07042253521126761\n",
      "[NN] noun, singular \"desk\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.06338028169014084\n",
      "[JJ] adjective\t\"big\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.035211267605633804\n",
      "[.] .\n",
      "\n",
      "-----\n",
      "\n",
      "0.035211267605633804\n",
      "[NNS] noun plural\t\"desks\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.028169014084507043\n",
      "[CC] coordinating conjunction\n",
      "\n",
      "-----\n",
      "\n",
      "0.028169014084507043\n",
      "[VBD] verb, past tense\ttook\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[PRP] personal pronound√ü\tI, he, she\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[PRP$] possessive pronoun\tmy, his, hers\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[RB] adverb\tvery, silently,\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[VBN] verb, past participle\ttaken\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[:] :\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[CD] cardinal digit\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[TO] to\tgo \"to\" the store.\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[VB] verb, base form\ttake\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[VBP] verb, sing. present, non-3d\ttake\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[WP] wh-pronoun\twho, what\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[(] (\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[)] )\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[POS] possessive ending\tparent\"s\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[VBZ] verb, 3rd person sing. present\ttakes\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "\n",
    "custom_sent_tokenizer = tokenize.PunktSentenceTokenizer(train_text)\n",
    "tokenized_text = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "total_counts = Counter()\n",
    "for i in tokenized_text[:5]:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    print('# Sentence:')\n",
    "    print(i)\n",
    "    print('# Words:')\n",
    "    print(words)\n",
    "    print('# Tagged:')\n",
    "    print(tagged)\n",
    "    counts = Counter(tag for word, tag in tagged)\n",
    "    total_counts += counts\n",
    "    print('\\n')\n",
    "\n",
    "total = sum(total_counts.values())\n",
    "freq = dict((word, float(count) / total) for word, count in sorted(total_counts.items()))\n",
    "print('# Counts:')\n",
    "print('\\n\\n-----\\n\\n'.join(['{}\\n[{}] {}'.format(f, tag, tag_to_description.get(tag, tag)) for tag, f in sorted(freq.items(), key=itemgetter(1), reverse=True)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "- [source](https://pythonprogramming.net/chunking-nltk-tutorial/)\n",
    "- [video](https://www.youtube.com/watch?v=imPpT2Qo2sk&index=5&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "no display name and no $DISPLAY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7f0485b269d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mchunked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunkParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# TODO: fix it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mchunked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mdraw_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[0;34m(*trees)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \"\"\"\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mTreeView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *trees)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLTK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-x>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2015\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2017\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2019\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "chunkParser = nltk.RegexpParser(chunkGram)\n",
    "\n",
    "for i in tokenized_text[:5]:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    chunked = chunkParser.parse(tagged)\n",
    "    # TODO: should fix it\n",
    "    # I'm using jupyter inside of Docker so maybe it is reason why doesn't work :(\n",
    "    # I've found this one https://stackoverflow.com/questions/31779707/how-do-you-make-nltk-draw-trees-that-are-inline-in-ipython-jupyter\n",
    "    # but haven't checkit it yet.\n",
    "    chunked.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
