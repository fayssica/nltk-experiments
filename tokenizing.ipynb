{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK experiments \n",
    "based on [NLTK with Python 3 for Natural Language Processing](https://www.youtube.com/playlist?list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL) by Sentdex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: we don't relly want to download packages each time when we lauch this script\n",
    "# so it'll better to check somehow whether we have packages or not - or Download on demand\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing\n",
    "based on \n",
    "- https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/\n",
    "- [youtube](https://www.youtube.com/watch?v=FLZvOKSCkxY&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = 'Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. ' \\\n",
    "          'The sky is pinkish-blue. You shouldn\\'t eat cardboard.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Mr. Smith, how are you doing today?',\n",
       " 'The weather is great, and Python is awesome.',\n",
       " 'The sky is pinkish-blue.',\n",
       " \"You shouldn't eat cardboard.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.sent_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Mr.',\n",
       " 'Smith',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " 'today',\n",
       " '?',\n",
       " 'The',\n",
       " 'weather',\n",
       " 'is',\n",
       " 'great',\n",
       " ',',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'is',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'The',\n",
       " 'sky',\n",
       " 'is',\n",
       " 'pinkish-blue',\n",
       " '.',\n",
       " 'You',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'eat',\n",
       " 'cardboard',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.word_tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stop words\n",
    "- [sources](https://pythonprogramming.net/stop-words-nltk-tutorial/)\n",
    "- [video](https://www.youtube.com/watch?v=w36-U-ccajM&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import corpus, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sentence = 'This is a sample sentence, showing off the stop words filtration.'\n",
    "stop_words = set(corpus.stopwords.words('english'))\n",
    "words = tokenize.word_tokenize(example_sentence)\n",
    "filtered_sentence = [w for w in words if w not in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "- [source](https://pythonprogramming.net/stemming-nltk-tutorial/)\n",
    "- [video](https://www.youtube.com/watch?v=yGKTphqxR9Q&index=3&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import stem, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = stem.PorterStemmer()\n",
    "example_words = ['python', 'pythoner', 'pythoning', 'pythoned', 'pythonly', 'pythonic', 'pythonista']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python --> python',\n",
       " 'pythoner --> python',\n",
       " 'pythoning --> python',\n",
       " 'pythoned --> python',\n",
       " 'pythonly --> pythonli',\n",
       " 'pythonic --> python',\n",
       " 'pythonista --> pythonista']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['{} --> {}'.format(w, ps.stem(w)) for w in example_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_text = 'It is important to by very pythonly while you are pythoning with python. '\\\n",
    "               'All pythoners have pythoned poorly at least once.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It --> It',\n",
       " 'is --> is',\n",
       " 'important --> import',\n",
       " 'to --> to',\n",
       " 'by --> by',\n",
       " 'very --> veri',\n",
       " 'pythonly --> pythonli',\n",
       " 'while --> while',\n",
       " 'you --> you',\n",
       " 'are --> are',\n",
       " 'pythoning --> python',\n",
       " 'with --> with',\n",
       " 'python --> python',\n",
       " '. --> .',\n",
       " 'All --> all',\n",
       " 'pythoners --> python',\n",
       " 'have --> have',\n",
       " 'pythoned --> python',\n",
       " 'poorly --> poorli',\n",
       " 'at --> at',\n",
       " 'least --> least',\n",
       " 'once --> onc',\n",
       " '. --> .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['{} --> {}'.format(w, ps.stem(w)) for w in tokenize.word_tokenize(example_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging\n",
    "- [source](https://pythonprogramming.net/part-of-speech-tagging-nltk-tutorial/)\n",
    "- [video](https://www.youtube.com/watch?v=6j6M2MtEqi8&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&index=4)\n",
    "\n",
    "```\n",
    "POS tag list:\n",
    "\n",
    "CC\tcoordinating conjunction\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW\tforeign word\n",
    "IN\tpreposition/subordinating conjunction\n",
    "JJ\tadjective\t'big'\n",
    "JJR\tadjective, comparative\t'bigger'\n",
    "JJS\tadjective, superlative\t'biggest'\n",
    "LS\tlist marker\t1)\n",
    "MD\tmodal\tcould, will\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "PDT\tpredeterminer\t'all tdhe kids'\n",
    "POS\tpossessive ending\tparent's\n",
    "PRP\tpersonal pronoundß\tI, he, she\n",
    "PRP$\tpossessive pronoun\tmy, his, hers\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "RP\tparticle\tgive up\n",
    "TO\tto\tgo 'to' the store.\n",
    "UH\tinterjection\terrrrrrrrm\n",
    "VB\tverb, base form\ttake\n",
    "VBD\tverb, past tense\ttook\n",
    "VBG\tverb, gerund/present participle\ttaking\n",
    "VBN\tverb, past participle\ttaken\n",
    "VBP\tverb, sing. present, non-3d\ttake\n",
    "VBZ\tverb, 3rd person sing. present\ttakes\n",
    "WDT\twh-determiner\twhich\n",
    "WP\twh-pronoun\twho, what\n",
    "WP$\tpossessive wh-pronoun\twhose\n",
    "WRB\twh-abverb\twhere, when\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import corpus, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = corpus.state_union.raw('2005-GWBush.txt')\n",
    "sample_text = corpus.state_union.raw('2006-GWBush.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_to_description = {\n",
    "    'CC': 'coordinating conjunction',\n",
    "    'CD': 'cardinal digit',\n",
    "    'DT': 'determiner',\n",
    "    'EX': 'existential there (like: \"there is\" ... think of it like \"there exists\")',\n",
    "    'FW': 'foreign word',\n",
    "    'IN': 'preposition/subordinating conjunction',\n",
    "    'JJ': 'adjective\t\"big\"',\n",
    "    'JJR': 'adjective, comparative\t\"bigger\"',\n",
    "    'JJS': 'adjective, superlative\t\"biggest\"',\n",
    "    'LS': 'list marker\t1)',\n",
    "    'MD': 'modal\tcould, will',\n",
    "    'NN': 'noun, singular \"desk\"',\n",
    "    'NNS': 'noun plural\t\"desks\"',\n",
    "    'NNP': 'proper noun, singular\t\"Harrison\"',\n",
    "    'NNPS': 'proper noun, plural\t\"Americans\"',\n",
    "    'PDT': 'predeterminer\t\"all tdhe kids\"',\n",
    "    'POS': 'possessive ending\tparent\"s',\n",
    "    'PRP': 'personal pronoundß\tI, he, she',\n",
    "    'PRP$': 'possessive pronoun\tmy, his, hers',\n",
    "    'RB': 'adverb\tvery, silently,',\n",
    "    'RBR': 'adverb, comparative\tbetter',\n",
    "    'RBS': 'adverb, superlative\tbest',\n",
    "    'RP': 'particle\tgive up',\n",
    "    'TO': 'to\tgo \"to\" the store.',\n",
    "    'UH': 'interjection\terrrrrrrrm',\n",
    "    'VB': 'verb, base form\ttake',\n",
    "    'VBD': 'verb, past tense\ttook',\n",
    "    'VBG': 'verb, gerund/present participle\ttaking',\n",
    "    'VBN': 'verb, past participle\ttaken',\n",
    "    'VBP': 'verb, sing. present, non-3d\ttake',\n",
    "    'VBZ': 'verb, 3rd person sing. present\ttakes',\n",
    "    'WDT': 'wh-determiner\twhich',\n",
    "    'WP': 'wh-pronoun\twho, what',\n",
    "    'WP$': 'possessive wh-pronoun\twhose',\n",
    "    'WRB': 'wh-abverb\twhere, when',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sentence:\n",
      "PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "January 31, 2006\n",
      "\n",
      "THE PRESIDENT: Thank you all.\n",
      "# Words:\n",
      "['PRESIDENT', 'GEORGE', 'W.', 'BUSH', \"'S\", 'ADDRESS', 'BEFORE', 'A', 'JOINT', 'SESSION', 'OF', 'THE', 'CONGRESS', 'ON', 'THE', 'STATE', 'OF', 'THE', 'UNION', 'January', '31', ',', '2006', 'THE', 'PRESIDENT', ':', 'Thank', 'you', 'all', '.']\n",
      "# Tagged:\n",
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "Mr. Speaker, Vice President Cheney, members of Congress, members of the Supreme Court and diplomatic corps, distinguished guests, and fellow citizens: Today our nation lost a beloved, graceful, courageous woman who called America to its founding ideals and carried on a noble dream.\n",
      "# Words:\n",
      "['Mr.', 'Speaker', ',', 'Vice', 'President', 'Cheney', ',', 'members', 'of', 'Congress', ',', 'members', 'of', 'the', 'Supreme', 'Court', 'and', 'diplomatic', 'corps', ',', 'distinguished', 'guests', ',', 'and', 'fellow', 'citizens', ':', 'Today', 'our', 'nation', 'lost', 'a', 'beloved', ',', 'graceful', ',', 'courageous', 'woman', 'who', 'called', 'America', 'to', 'its', 'founding', 'ideals', 'and', 'carried', 'on', 'a', 'noble', 'dream', '.']\n",
      "# Tagged:\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "Tonight we are comforted by the hope of a glad reunion with the husband who was taken so long ago, and we are grateful for the good life of Coretta Scott King.\n",
      "# Words:\n",
      "['Tonight', 'we', 'are', 'comforted', 'by', 'the', 'hope', 'of', 'a', 'glad', 'reunion', 'with', 'the', 'husband', 'who', 'was', 'taken', 'so', 'long', 'ago', ',', 'and', 'we', 'are', 'grateful', 'for', 'the', 'good', 'life', 'of', 'Coretta', 'Scott', 'King', '.']\n",
      "# Tagged:\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "(Applause.)\n",
      "# Words:\n",
      "['(', 'Applause', '.', ')']\n",
      "# Tagged:\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "\n",
      "\n",
      "# Sentence:\n",
      "President George W. Bush reacts to applause during his State of the Union Address at the Capitol, Tuesday, Jan.\n",
      "# Words:\n",
      "['President', 'George', 'W.', 'Bush', 'reacts', 'to', 'applause', 'during', 'his', 'State', 'of', 'the', 'Union', 'Address', 'at', 'the', 'Capitol', ',', 'Tuesday', ',', 'Jan', '.']\n",
      "# Tagged:\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n",
      "\n",
      "\n",
      "# Counts:\n",
      "0.29577464788732394\n",
      "[NNP] proper noun, singular\t\"Harrison\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.09859154929577464\n",
      "[IN] preposition/subordinating conjunction\n",
      "\n",
      "-----\n",
      "\n",
      "0.07746478873239436\n",
      "[,] ,\n",
      "\n",
      "-----\n",
      "\n",
      "0.07042253521126761\n",
      "[DT] determiner\n",
      "\n",
      "-----\n",
      "\n",
      "0.07042253521126761\n",
      "[NN] noun, singular \"desk\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.06338028169014084\n",
      "[JJ] adjective\t\"big\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.035211267605633804\n",
      "[.] .\n",
      "\n",
      "-----\n",
      "\n",
      "0.035211267605633804\n",
      "[NNS] noun plural\t\"desks\"\n",
      "\n",
      "-----\n",
      "\n",
      "0.028169014084507043\n",
      "[CC] coordinating conjunction\n",
      "\n",
      "-----\n",
      "\n",
      "0.028169014084507043\n",
      "[VBD] verb, past tense\ttook\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[PRP] personal pronoundß\tI, he, she\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[PRP$] possessive pronoun\tmy, his, hers\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[RB] adverb\tvery, silently,\n",
      "\n",
      "-----\n",
      "\n",
      "0.02112676056338028\n",
      "[VBN] verb, past participle\ttaken\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[:] :\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[CD] cardinal digit\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[TO] to\tgo \"to\" the store.\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[VB] verb, base form\ttake\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[VBP] verb, sing. present, non-3d\ttake\n",
      "\n",
      "-----\n",
      "\n",
      "0.014084507042253521\n",
      "[WP] wh-pronoun\twho, what\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[(] (\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[)] )\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[POS] possessive ending\tparent\"s\n",
      "\n",
      "-----\n",
      "\n",
      "0.007042253521126761\n",
      "[VBZ] verb, 3rd person sing. present\ttakes\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "\n",
    "custom_sent_tokenizer = tokenize.PunktSentenceTokenizer(train_text)\n",
    "tokenized_text = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "total_counts = Counter()\n",
    "for i in tokenized_text[:5]:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    print('# Sentence:')\n",
    "    print(i)\n",
    "    print('# Words:')\n",
    "    print(words)\n",
    "    print('# Tagged:')\n",
    "    print(tagged)\n",
    "    counts = Counter(tag for word, tag in tagged)\n",
    "    total_counts += counts\n",
    "    print('\\n')\n",
    "\n",
    "total = sum(total_counts.values())\n",
    "freq = dict((word, float(count) / total) for word, count in sorted(total_counts.items()))\n",
    "print('# Counts:')\n",
    "print('\\n\\n-----\\n\\n'.join(['{}\\n[{}] {}'.format(f, tag, tag_to_description.get(tag, tag)) for tag, f in sorted(freq.items(), key=itemgetter(1), reverse=True)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
